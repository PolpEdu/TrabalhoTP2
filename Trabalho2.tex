
\documentclass[12pt,journal,compsoc]{IEEEtran}


\ifCLASSOPTIONcompsoc
  \usepackage[nocompress]{cite}
\else
  \usepackage{cite}
\fi

\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi

\usepackage{amsmath}
\usepackage[bottom]{footmisc}
\usepackage{graphicx} %imagens






% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
\graphicspath{ {./images/} }

% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Teoria da Informação\\2º Trabalho Prático\\CODEC não destrutivo para Texto}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%
%
%\IEEEcompsocitemizethanks is a special \thanks that produces the bulleted
% lists the Computer Society journals use for "first footnote" author
% affiliations. Use \IEEEcompsocthanksitem which works much like \item
% for each affiliation group. When not in compsoc mode,
% \IEEEcompsocitemizethanks becomes like \thanks and
% \IEEEcompsocthanksitem becomes a line break with idention. This
% facilitates dual compilation, although admittedly the differences in the
% desired content of \author between the different types of papers makes a
% one-size-fits-all approach a daunting prospect. For instance, compsoc 
% journal papers have the author affiliations above the "Manuscript
% received ..."  text while in non-compsoc journals this is reversed. Sigh.

\author{Eduardo~Nunes,~\IEEEmembership{~2020217675,}
        André~Moreira,~\IEEEmembership{~2020239416}
        e~Diogo~Tavares,~\IEEEmembership{~2020236566}% <-this % stops a space
\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem Docente da cadeira: Paulo Fernando Pereira de Carvalho.
\IEEEcompsocthanksitem Docente da aula: Marco António Machado Simões \protect\\Grupo 5 da turma PL6.}% <-this % stops an unwanted space
\thanks{Trabalho realizado com base nos conhecimentos\\ obtidos na cadeira da Teoria da Informação.}}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
\markboth{Trabalho TEORIA DA INFORMAÇÃO n.º~2\> \>Parte 1, Novembro~2021}
{\MakeLowercase{\textit{et al.}}}%

% in the abstract or keywords.
\IEEEtitleabstractindextext{%
\begin{abstract}
Neste trabalho prático exploramos conceitos de Teoria de Informação, em particular, relativos à Teoria da Compressão. Pretendemos responder, principalmente, à questão: Quais serão os algoritmos mais eficazes de compressão não destrutiva de texto e as suas principais diferenças?\\ Para isto, calculamos o limite mínimo teórico para o número médio de bits por símbolo, a Entropia, para cada uma das fontes fornecidas (todas baseadas em documentos de texto) e, seguidamente, comprimimos essas fontes com diversos algoritmos de compressão de texto monitorizando, por fim, o número médio de bits por símbolo, verificando assim, quais destes se aproximam mais da Entropia de acordo com o CODEC utilizado. Os algoritmos ideais foram aqueles que se aproximaram mais da Entropia consistentemente nas diversas fontes e não abdicaram de muito poder e tempo de processamento para a sua codificação.
% acabar abstract no final
\end{abstract}

% Note that keywords are not normally used for peer review papers.
\begin{IEEEkeywords}
Teoria da Informação, IEEE, CODECs, \LaTeX, algoritmos, compressão de texto, Python.
\end{IEEEkeywords}}


% make the title area
\maketitle


% To allow for easy dual compilation without having to reenter the
% abstract/keywords data, the \IEEEtitleabstractindextext text will
% not be used in maketitle, but will appear (i.e., to be "transported")
% here as \IEEEdisplaynontitleabstractindextext when the compsoc 
% or transmag modes are not selected <OR> if conference mode is selected 
% - because all conference papers position the abstract like regular
% papers do.
\IEEEdisplaynontitleabstractindextext
% \IEEEdisplaynontitleabstractindextext has no effect when using
% compsoc or transmag under a non-conference mode.



% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\IEEEraisesectionheading{\section{Introdução}\label{sec:introduction}}

\subsection{Problema e a sua importância}
\IEEEPARstart{E}{ste} trabalho visa encontrar uma solução para a compressão eficiente não destrutiva de texto. Um dos pilares da vida humana é \textbf{transmitir informação o mais rapidamente possível}, primeiro fisicamente através de cartas, sinais luminosos, sinais sonoros, impulsos elétricos e na \textbf{atualidade essencialmente através de bits digitais}. A determinada altura \textbf{é certo de que iremos chegar a um limite físico da rapidez com que enviamos bits}. Se continuarmos a necessitar de enviar grandes quantidades de informação com cada vez maior rapidez, é necessário encontrar uma maneira de representar a mesma informação com menor número de bits – \textbf{é crucial comprimir a data a enviar.}



\subsection{Implementação}


É de realçar que \textbf{o foco desta pesquisa não reside na implementação propriamente dita, mas sim na sua fundamentação e validação}. Nesse sentido, decidimos demonstrar o código dos diferentes CODECs\footnote{CODEC significa "Coder-Decoder", algoritmo de compressão de data de modo a transmiti-la mais rapidamente.} com base na linguagem \textit{Python} devido à sua facilidade de leitura, à sua fácil implementação, caso o leitor pretenda testar os algoritmos apresentados, e ao fácil acesso de módulos que podem auxiliar o tratamento de dados das fontes.

% needed in second column of first page if using \IEEEpubid
\IEEEpubidadjcol

\subsubsection{Dados por base}
%explicar melhor
Devido a esta notável questão, pretendemos, usando 4 fontes de texto distintas como exemplo:

\begin{enumerate}
    \item \textit{bible.txt}: Ficheiro de texto composto por uma transcrição da Bíblia.
    \item \textit{finance.csv}: Ficheiro de texto composto por data separada por vírgulas.
    \item \textit{jquery-3.6.0.js}: Ficheiro de texto composto pelo código fonte da livraria de \textit{JavaScript}:\textit{Jquery}.
    \item \textit{random.txt}: Ficheiro de texto composto por um conjunto de caracteres aleatório.
\end{enumerate}

Para codificar estas fontes é indispensável referir que haverá CODECs melhores do que outros dependendo da fonte selecionada. Pretende-se, portanto, encontrar não um CODEC ideal para uma determinada fonte, mas sim \textbf{o mais eficaz geralmente}. 

% Esse estado da arte deverá versar pelo menos os seguintes aspectos: principais  módulos dos codecs e transformadas aplicáveis no domínio do texto e principais códigos usados, bem como a suas combinações
\subsection{\textit{State of the art}}
Como foi referido inicialmente, para o ser humano viver em sociedade é indispensável transmitir informação o mais rapidamente possível, por isso, é essencial haver um constante avanço (nem que seja mínimo) por parte dos estudos da matéria em causa. O uso de um algoritmo ideal de compressão sem perdas de data é, obviamente, muito dependente do tipo de data em causa.
Atualmente, é essencial ter em conta o tipo de data a codificar na sua codificação, apesar de existirem CODECs não destrutivos para todo o tipo de data em geral.

\subsubsection{Codificação Delta Encoding} 
Um bom exemplo da importância da dependência de data é visto quando se codifica uma imagem, atualmente, seria mais vantajoso codifica-la em \textit{PNG}\footnote{significa \textit{"Portable Network Graphics"}, um formato de codificação sem perdas de data para imagens.} do que usando a codificação \textit{LZ77} (apesar desta não necessitar \textit{à priori} do conhecimento da estrutura da fonte). Como se trata de uma imagem o método \textit{PNG} usa uma versão de  \textit{Delta Encoding} ao fazer \textit{Filtering}, onde em vez de representar todos os valores de uma dada fonte, representamos a diferença entre eles o que é muito útil em imagens visto que os pixeis estão usualmente correlacionados.

\begin{figure}[htp]
\includegraphics[width=0.5\textwidth]{deltaenc.png}
\caption{Exemplo de uma codificação atual para imagens: \textit{Delta Encoding}, a data codificada é obtida pela a diferença do valor anterior. Em imagens (no formato \textit{PNG}), em vez de números á direita, tem-se pixeis em diferentes posições.}
\end{figure}

% pedir ao stor para rever erros teóricos nesta parte:
\subsubsection{Codificação de Huffman} 

O Código de Huffman, um código ótimo devido a nenhum código ser prefixo\footnote{Um código diz-se "de prefixo" quando nenhuma palavra é prefixo da outra, ou seja, um código de prefixo é um código unicamente descodificável.} um do outro, é sem dúvida um dos métodos de compressão mais conhecidos devido à sua simplicidade, fácil implementação, eficácia e não ter patente daí esta codificação ser amplamente usada em aplicações de compressão que vão de \textit{GZIP}, \textit{PKZIP}, \textit{BZIP2} a formatos de imagem como \textit{PNG} e \textit{JPEG}.

Esta codificação consiste em:
\begin{enumerate}
    \item Ordenar os símbolos por ordem crescente de ocorrências
    \item Construir uma árvore binária até não haver mais símbolos:
    \begin{enumerate}
        \item Combinar os dois símbolos menos frequentes num único símbolo (cada folha é um símbolo sendo, portanto, um bit com um valor de 1 ou 0)
        \item Acrescentar o novo símbolo à lista em que a frequência é a soma das frequências individuais.
    \end{enumerate}
\end{enumerate}
A eficácia desta codificação reside no facto dos símbolos que ocorrem mais vezes sejam codificados com menos bits, estando os símbolos com mais ocorrências mais próximos da raiz da árvore binária.

A eficiência do código é dada por:
\begin{center}
\begin{math}H(S)\leq\Bar{l}<H(S)+1\end{math}\\
\small Sendo \begin{math}H(S)\end{math} a entropia, \begin{math}\Bar{l}\end{math} o número de bits médio.  
\end{center}

Apesar da sua grande eficiência, infelizmente, é de grande importância referir que não é perfeito. Além de também termos que codificar a árvore binária gerada depois de codificar a fonte o código de Huffman assume que:
\begin{enumerate}
    \item A data usada é independente, ou seja, que os valores a comprimir são independentes, o que geralmente não são\footnote{Como foi referido no inicio do deste Capitulo a dependência da data é muito importante quando queremos reduzir a entropia, é importante saber o tipo de data que queremos comprimir porque sabemos que dependências tomar partido de para obter uma codificação ideal}.
    \item Tem de existir o modelo da distribuição estatística. Uma resposta para este problema foi o \textit{Modelo Adaptativo de Huffman}.
\end{enumerate}


Para terminar, uma tentativa de optimização da \textbf{codificação de Huffman} foi tentar agrupar vários símbolos de modo a aumentar a dependência interna entre eles, no entanto, não se costuma fazer isto porque se um alfabeto tiver $m$ símbolos, um agrupamento $n$ implica um alfabeto com $m^n$ símbolos (o número de símbolos cresce exponencialmente o que em termos de memória não é ideal). Uma solução usada foram os \textit{Códigos Aritméticos}. %este paragrafo está correto? Perguntar stor

%\url{https://en.wikipedia.org/wiki/Huffman_coding#Adaptive_Huffman_coding
\subsubsection{Codificação LZ78}



\subsubsection{Codificação Run-Lenght-Encoding}
\subsubsection{Codificação Burrows-Wheeler}
A Codificação Burrows-Wheeler consiste em, dada uma cadeia de comprimento $N$, criamos sequências 

\subsubsection{Codificação Move-to-Front}
Este método consiste em codificar uma string substituindo cada símbolo com a sua respetiva posição no array. Em cada substituição, será realocada a posição desse símbolo no array, sendo este movido para o início do mesmo. Assim, no final, os símbolos que foram mais recentemente usados, estarão no início do array.


Para o nosso trabalho usaremos as combinações
\begin{enumerate}
    \item \textbf{Codificação de Huffman}
    \item \textbf{Codificação LZW + Huffman}, uma junção que normalmente resulta em compressões muito boas, visto que depois de codificar em LZW, um conjunto de bits, como por exemplo, 000 pode ser representado por um só bit 0.
    \item \textbf{Codificação Burrows Wheeler + Run-Lenght-Encoding}, uma combinação que 
    
    \item \textbf{Codificação Move to Front + Huffman}
\end{enumerate}


\section{Métodos}\label{sec:metodos}
Começámos então, por explorar o \textit{Dataset} a comprimir composto por 4 fontes de texto distintas, calculando a Entropia\footnote{limite mínimo teórico para o número médio de bits por símbolo} de cada fonte e a sua distribuição estatística.\\
E seguidamente, comprimimos as diferentes fontes usando 5 algoritmos de compressão diferentes:

\begin{enumerate}
    \item Codificação de Huffman
    \item Codificação LZW + Huffman \textit{()}
    \item Codificação Burrows Wheeler + RLE\textit{()}
    \item Codificação Move to Front + Huffman \textit{()}
\end{enumerate}


Calculando finalmente, depois dos ficheiros comprimidos, o número médio de bits por símbolo atual de modo a comparar com a entropia inicial e verificar a eficácia da compressão de data em causa.

\section{Resultados} %no geral
Os resultados 


% Entropia de bible.txt: 4.34275 bits/simbolo
% Entropia de finance.csv: 5.15995 bits/simbolo
% Entropia de jquery-3.6.0.js: 5.06698 bits/simbolo
% Entropia de random.txt: 6.00000 bits/simbolo

\subsection{Conclusões}
Dos resultados, concluímos que a codificação



\appendices
\section{Proof of the First Zonklar Equation}
Appendix one text goes here.

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
\section{}
Appendix two text goes here.


% use section* for acknowledgment
\ifCLASSOPTIONcompsoc
  % The Computer Society usually uses the plural form
  \section*{Acknowledgments}
\else
  % regular IEEE prefers the singular form
  \section*{Acknowledgment}
\fi

The authors would like to thank...

\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

\begin{thebibliography}{1}

\bibitem{IEEEhowto:kopka}
H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

\end{thebibliography}

\footnotemark 


% that's all folks
\end{document}


